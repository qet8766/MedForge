#!/usr/bin/env bash
#
# Phase 5 competition platform validation.
# Runs competition API and scoring lanes for contract fields, scoring, caps, and leaderboard rules.

set -euo pipefail

ROOT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")/../.." && pwd)"
PHASE_ID="phase5-competitions"
RUN_ID="$(date -u +%Y%m%dT%H%M%SZ)"
EVIDENCE_DIR="${EVIDENCE_DIR:-${ROOT_DIR}/docs/evidence/$(date -u +%F)}"
EVIDENCE_FILE="${EVIDENCE_FILE:-${EVIDENCE_DIR}/${PHASE_ID}-${RUN_ID}.md}"
LOG_FILE="${LOG_FILE:-${EVIDENCE_DIR}/${PHASE_ID}-${RUN_ID}.log}"

PHASE_STATUS="INCONCLUSIVE"

usage() {
  cat <<'USAGE'
Usage: bash ops/host/validate-phase5-competitions.sh

Optional env:
  EVIDENCE_DIR=docs/evidence/<date>
  EVIDENCE_FILE=<explicit markdown path>
  LOG_FILE=<explicit log path>
USAGE
}

require_cmd() {
  local cmd="$1"
  if ! command -v "${cmd}" >/dev/null 2>&1; then
    echo "ERROR: required command not found: ${cmd}"
    exit 1
  fi
}

record() {
  local line="$1"
  printf "%s\n" "${line}" >>"${EVIDENCE_FILE}"
}

run_check() {
  local name="$1"
  local cmd="$2"

  record "### ${name}"
  record ""
  record '```bash'
  record "${cmd}"
  record '```'

  if eval "${cmd}" >>"${LOG_FILE}" 2>&1; then
    record "- status: PASS"
  else
    record "- status: FAIL"
    record "- log: \`${LOG_FILE}\`"
    exit 1
  fi
  record ""
}

cleanup() {
  local exit_code=$?
  if [ "${PHASE_STATUS}" != "PASS" ] && [ -f "${EVIDENCE_FILE}" ]; then
    record "## Verdict"
    record "- phase: \`${PHASE_ID}\`"
    record "- status: FAIL"
    record "- log: \`${LOG_FILE}\`"
  fi
  exit "${exit_code}"
}
trap cleanup EXIT

run_competition_api_tests() {
  cd "${ROOT_DIR}/apps/api"

  if [ ! -d ".venv" ]; then
    echo "ERROR: apps/api/.venv not found."
    return 1
  fi

  # shellcheck source=/dev/null
  . .venv/bin/activate

  pytest -q \
    tests/test_api.py::test_list_competitions \
    tests/test_api.py::test_competition_detail_status \
    tests/test_api.py::test_competition_detail_missing_returns_problem_404 \
    tests/test_api.py::test_dataset_missing_returns_problem_404 \
    tests/test_api.py::test_submit_and_score_titanic \
    tests/test_api.py::test_submit_and_score_rsna_detection \
    tests/test_api.py::test_submit_and_score_cifar100 \
    tests/test_api.py::test_submission_cap_enforced \
    tests/test_api.py::test_invalid_schema_rejected \
    tests/test_api.py::test_leaderboard_respects_higher_is_better_flag \
    tests/test_api.py::test_leaderboard_rejects_invalid_pagination \
    tests/test_api.py::test_list_my_submissions_returns_desc_created_order \
    tests/test_api.py::test_submission_internal_failure_returns_problem_500 \
    tests/test_api.py::test_submission_rejects_disallowed_origin \
    tests/test_api.py::test_admin_score_rejects_disallowed_origin \
    tests/test_api.py::test_admin_score_missing_submission_returns_problem_404 \
    tests/test_api.py::test_admin_score_requires_admin_role \
    tests/test_api.py::test_submission_upload_size_limit_returns_structured_422
}

run_scoring_tests() {
  cd "${ROOT_DIR}/apps/api"

  # shellcheck source=/dev/null
  . .venv/bin/activate

  pytest -q tests/test_scoring.py
}

main() {
  if [ "${1:-}" = "-h" ] || [ "${1:-}" = "--help" ]; then
    usage
    exit 0
  fi

  mkdir -p "${EVIDENCE_DIR}"
  : >"${LOG_FILE}"

  {
    echo "## Phase 5 Competition Platform Evidence ($(date -u +%F))"
    echo ""
    echo "Generated by: \`ops/host/validate-phase5-competitions.sh\`"
    echo ""
    echo "Runtime:"
    echo "- run id: \`${RUN_ID}\`"
    echo ""
  } >"${EVIDENCE_FILE}"

  run_check "Competition API Contract Lanes" "run_competition_api_tests"
  run_check "Competition Scoring Determinism Lanes" "run_scoring_tests"

  PHASE_STATUS="PASS"
  record "## Verdict"
  record "- phase: \`${PHASE_ID}\`"
  record "- status: PASS"
  record "- log: \`${LOG_FILE}\`"

  echo "Validation complete: ${EVIDENCE_FILE}"
}

main "$@"
